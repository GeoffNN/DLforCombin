{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tsp_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "embedding_size = 128\n",
    "max_time_steps = 10; input_size = 2;\n",
    "batch_size = 128\n",
    "initialization_stddev = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "enc_inputs = tf.placeholder(tf.float32, [batch_size, max_time_steps, input_size])\n",
    "W_embed = tf.Variable(tf.random_normal([embedding_size, input_size],\n",
    "                                       stddev=initialization_stddev))\n",
    "embedded_inputs = tf.einsum('kl,itl->itk', W_embed, enc_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rnn encoder\n",
    "# with tf.variable_scope(\"encoder\"):\n",
    "#     enc_rnn_cell = tf.nn.rnn_cell.LSTMCell(hidden_size)\n",
    "#     enc_outputs, enc_final_state = tf.nn.dynamic_rnn(cell=enc_rnn_cell, \n",
    "#                                                      inputs=embedded_inputs,\n",
    "#                                                      dtype=tf.float32)\n",
    "\n",
    "# dilated CNN encoder\n",
    "def makeCNNLayer(inputs, filters, dilation, residual=False, kernel_size=2):\n",
    "    gate = tf.sigmoid(tf.layers.conv1d(inputs = inputs,\n",
    "                          filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          dilation_rate = dilation,\n",
    "                          padding=\"SAME\",\n",
    "                          activation=None,\n",
    "                          trainable = True))\n",
    "    fil = tf.tanh(tf.layers.conv1d(inputs = inputs,\n",
    "                          filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          dilation_rate = dilation,\n",
    "                          padding=\"SAME\",\n",
    "                          activation=None,\n",
    "                          trainable = True))\n",
    "    \n",
    "    out = gate * fil\n",
    "    \n",
    "    if residual:\n",
    "        return inputs + out\n",
    "    else:\n",
    "        return out\n",
    "\n",
    "# ordering required: batch size, max time step, num channels = embedding size\n",
    "with tf.variable_scope(\"encoder\"):\n",
    "    conv = []\n",
    "    conv.append(makeCNNLayer(embedded_inputs, filters=hidden_size/4, dilation=1))\n",
    "\n",
    "    # make the other layers\n",
    "    numDilationLayer = 3\n",
    "    factors = [2, 4, 8]\n",
    "    for layerNum in range(0, numDilationLayer):\n",
    "        conv.append(makeCNNLayer(conv[-1], filters=hidden_size/4, dilation=factors[layerNum], residual=True))\n",
    "        \n",
    "    # for output just concatenate all the convolution outputs \n",
    "    enc_outputs = tf.concat(conv, axis=2)\n",
    "    \n",
    "    # avg pooling to mimic lstm state (don't use tf.nn.pool because those require predetermined window size)\n",
    "    enc_final_state_c = tf.reduce_mean(enc_outputs, axis=1)\n",
    "    \n",
    "    # for \"LSTM output (h)\" do relu(c)\n",
    "    enc_final_state = tf.nn.rnn_cell.LSTMStateTuple(c = enc_final_state_c, h = tf.nn.relu(enc_final_state_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_mask(W_ref, W_q, v, enc_outputs, query, already_played_actions=None, \n",
    "                   already_played_penalty=1e6):\n",
    "    with tf.variable_scope(\"attention_mask\"):\n",
    "        u_i0s = tf.einsum('kl,itl->itk', W_ref, enc_outputs)\n",
    "        u_i1s = tf.expand_dims(tf.einsum('kl,il->ik', W_q, query), 1)\n",
    "        u_is = tf.einsum('k,itk->it', v, tf.tanh(u_i0s + u_i1s)) - already_played_penalty * already_played_actions\n",
    "        return u_is, tf.nn.softmax(u_is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoder\"):\n",
    "    decoder_cell = tf.nn.rnn_cell.LSTMCell(hidden_size)\n",
    "    decoder_state = [enc_final_state]\n",
    "    first_decoder_input = tf.tile(tf.Variable(tf.random_normal([1, embedding_size]), \n",
    "                                      name='first_decoder_input'), [batch_size, 1])\n",
    "    \n",
    "    decoder_targets = tf.placeholder(dtype=tf.int32, shape=[batch_size, max_time_steps])\n",
    "    \n",
    "    with tf.variable_scope(\"attention_weights\", reuse=True):\n",
    "        W_ref = tf.Variable(tf.random_normal([embedding_size, embedding_size],\n",
    "                                             stddev=initialization_stddev),\n",
    "                           name='W_ref')\n",
    "        W_q = tf.Variable(tf.random_normal([embedding_size, embedding_size],\n",
    "                                           stddev=initialization_stddev),\n",
    "                         name='W_q')\n",
    "        v = tf.Variable(tf.random_normal([embedding_size], stddev=initialization_stddev),\n",
    "                        name='v')\n",
    "    \n",
    "    # Training chain\n",
    "    loss = 0\n",
    "    # apply l2 regularization on the encoder kernels\n",
    "    for i in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"encoder\"):\n",
    "        if \"kernel\" in i.name:\n",
    "            loss += tf.nn.l2_loss(i)\n",
    "    loss *= 0.001\n",
    "    decoder_input = first_decoder_input\n",
    "    decoder_state = enc_final_state\n",
    "    already_played_actions = tf.zeros(shape=[batch_size, max_time_steps], dtype=tf.float32)\n",
    "    decoder_inputs = [decoder_input]\n",
    "    for t in range(max_time_steps):\n",
    "        dec_cell_output, decoder_state = decoder_cell(inputs=decoder_input, \n",
    "                                          state=decoder_state)\n",
    "        attn_logits, _ = attention_mask(W_ref, W_q, v, enc_outputs, dec_cell_output,\n",
    "                                        already_played_actions=already_played_actions,\n",
    "                                        already_played_penalty=1e6)\n",
    "        loss += tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(decoder_targets[:, t],\n",
    "                                                                          depth=max_time_steps),\n",
    "                                                        logits=attn_logits))\n",
    "        loss_summary_sy = tf.summary.scalar('training_loss', loss)\n",
    "\n",
    "        # Teacher forcing of the next input\n",
    "        decoder_input = tf.einsum('itk,it->ik', embedded_inputs,\n",
    "                                  tf.one_hot(decoder_targets[:, t], depth=max_time_steps))\n",
    "        decoder_inputs.append(decoder_input)\n",
    "        already_played_actions += tf.one_hot(decoder_targets[:, t], depth=max_time_steps)\n",
    "    \n",
    "    # Inference chain\n",
    "    decoder_input = first_decoder_input\n",
    "    decoder_state = enc_final_state\n",
    "    decoder_outputs = []\n",
    "    already_played_actions = tf.zeros(shape=[batch_size, max_time_steps], dtype=tf.float32)\n",
    "    for t in range(max_time_steps):\n",
    "        dec_cell_output, decoder_state = decoder_cell(inputs=decoder_input,\n",
    "                                                      state=decoder_state)\n",
    "        _, attn_mask = attention_mask(W_ref, W_q, v, enc_outputs, dec_cell_output,\n",
    "                                      already_played_actions=already_played_actions,\n",
    "                                      already_played_penalty=1e6)\n",
    "        decoder_outputs.append(tf.argmax(attn_mask, axis=1))\n",
    "        decoder_input = tf.einsum('itk,it->ik', embedded_inputs, attn_mask)\n",
    "        already_played_actions += tf.one_hot(decoder_outputs[-1], depth=max_time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(1e-2)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a batch of data\n",
    "def generate_batch(n_cities, batch_size):\n",
    "    inputs_list = []; labels_list = []\n",
    "    env = tsp_env.TSP_env(n_cities, use_alternative_state=True)\n",
    "    for i in range(batch_size):\n",
    "        env.reset()\n",
    "        s = env.reset()\n",
    "        coords = s.reshape([4, n_cities])[:2, ].T\n",
    "        inputs_list.append(coords)\n",
    "        labels_list.append(env.optimal_solution()[1])\n",
    "    return np.array(inputs_list), np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "log_files_name = 'PointerNet-TSP5'\n",
    "writer = tf.summary.FileWriter('/tmp/' + log_files_name, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1931.92\n",
      "1.8749954278\n",
      "1058.84\n",
      "1.41548477067\n",
      "532.338\n",
      "1.11065990955\n",
      "482.544\n",
      "1.10734687692\n",
      "506.458\n",
      "1.08216942815\n",
      "455.475\n",
      "1.07622647956\n",
      "459.332\n",
      "1.07360818244\n",
      "399.774\n",
      "1.06336138256\n",
      "452.34\n",
      "1.06053828749\n",
      "431.539\n",
      "1.06952395482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-122f1e69f23f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmean_approx_ratios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minputs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     loss_summary, loss_val, _ = sess.run([loss_summary_sy, loss, train_op], feed_dict={enc_inputs: inputs_batch, \n\u001b[1;32m      8\u001b[0m                                                         decoder_targets: labels_batch})\n",
      "\u001b[0;32m<ipython-input-8-3745fa875407>\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(n_cities, batch_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minputs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlabels_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimal_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/borislo/Class/deepTimeSeriesProj/DQN_and_AC-MVC-TSP-Knapsack/tsp_env.py\u001b[0m in \u001b[0;36moptimal_solution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mC\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                     B[(S, j)] = min([(A[(S - {j}, k)][0] + all_distances[k][j], A[(S - {j}, k)][1] + [j]) for k in S if\n\u001b[0m\u001b[1;32m    118\u001b[0m                                      k != 0 and k != j])  # this will use 0th index of tuple for ordering, the same as if key=itemgetter(0) used\n\u001b[1;32m    119\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/borislo/Class/deepTimeSeriesProj/DQN_and_AC-MVC-TSP-Knapsack/tsp_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     B[(S, j)] = min([(A[(S - {j}, k)][0] + all_distances[k][j], A[(S - {j}, k)][1] + [j]) for k in S if\n\u001b[0;32m--> 118\u001b[0;31m                                      k != 0 and k != j])  # this will use 0th index of tuple for ordering, the same as if key=itemgetter(0) used\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mall_distances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_cities = 10\n",
    "\n",
    "loss_vals = []\n",
    "mean_approx_ratios = []\n",
    "for i in range(2000):\n",
    "    inputs_batch, labels_batch = generate_batch(n_cities, batch_size)\n",
    "    loss_summary, loss_val, _ = sess.run([loss_summary_sy, loss, train_op], feed_dict={enc_inputs: inputs_batch, \n",
    "                                                        decoder_targets: labels_batch})\n",
    "    loss_vals.append(loss_val)\n",
    "    \n",
    "    # Add training loss to tensorboard logs\n",
    "    if i % 100 == 0:\n",
    "        writer.add_summary(loss_summary, i)\n",
    "        writer.flush()\n",
    "        print(loss_vals[-1])\n",
    "        \n",
    "    # Test accuracy\n",
    "    if i % 100 == 0:\n",
    "        envs = []\n",
    "        inputs_list = []\n",
    "        optimal_rewards = []\n",
    "        optimal_tours = []\n",
    "        # Generate and initialize a batch of environments\n",
    "        for i in range(batch_size):\n",
    "            envs.append(tsp_env.TSP_env(n_cities, use_alternative_state=True))\n",
    "            envs[-1].reset()\n",
    "            inputs_list.append(envs[-1].nodes)\n",
    "            optimal_solution = envs[-1].optimal_solution()\n",
    "            optimal_rewards.append(optimal_solution[0])\n",
    "            optimal_tours.append(optimal_solution[1])\n",
    "        inputs_batch = np.array(inputs_list)\n",
    "        # Use the PointerNet on this test batch and get its predictions\n",
    "        predicted_outputs = np.array(sess.run(decoder_outputs, \n",
    "                                              feed_dict={enc_inputs: inputs_batch})).T\n",
    "        # Compute the rewards corresponding to the predicted tours\n",
    "        rewards = []\n",
    "        for i in range(batch_size):\n",
    "            for action in predicted_outputs[i]:\n",
    "                envs[i].step(action)\n",
    "            rewards.append(envs[i].accumulated_reward())\n",
    "        # Get the approximation ratio of the predictions\n",
    "        approximation_ratios = np.array(rewards) / np.array(optimal_rewards)\n",
    "        mean_approx_ratios.append(np.mean(approximation_ratios))\n",
    "        print(mean_approx_ratios[-1])\n",
    "\n",
    "# Plot the training losses\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(loss_vals)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1932.71\n",
    "1.84706581207\n",
    "1164.02\n",
    "1.43337082941\n",
    "843.223\n",
    "1.23827504926\n",
    "516.45\n",
    "1.08655902801\n",
    "539.293\n",
    "1.05318710247\n",
    "442.764\n",
    "1.07505060358\n",
    "441.321\n",
    "1.05859506978\n",
    "429.605\n",
    "1.09639691263\n",
    "414.12\n",
    "1.06063726765\n",
    "407.63\n",
    "1.06324440677\n",
    "406.542\n",
    "1.0674630074\n",
    "394.631\n",
    "1.06518062815\n",
    "433.739\n",
    "1.05594344493\n",
    "403.762\n",
    "1.05361630671\n",
    "368.75\n",
    "1.06584705366\n",
    "449.005\n",
    "1.05865283626\n",
    "370.119\n",
    "1.05501567571\n",
    "394.252\n",
    "1.0631991011\n",
    "363.634\n",
    "1.04804667828\n",
    "424.288\n",
    "1.05605431789\n",
    "\n",
    "\n",
    "1931.56\n",
    "1.81436837541\n",
    "1195.94\n",
    "1.47673060703\n",
    "1105.63\n",
    "1.42435116841\n",
    "601.473\n",
    "1.11164770218\n",
    "495.248\n",
    "1.07649241426\n",
    "475.708\n",
    "1.0815006505\n",
    "453.345\n",
    "1.06482116029\n",
    "462.022\n",
    "1.08313822775\n",
    "426.967\n",
    "1.07263589667\n",
    "402.586\n",
    "1.05350172193\n",
    "403.404\n",
    "1.08291738133\n",
    "392.474\n",
    "1.06485440495\n",
    "445.153\n",
    "1.06631797562\n",
    "431.847\n",
    "1.0560231302\n",
    "458.896\n",
    "1.06459694357\n",
    "405.47\n",
    "1.06396575731\n",
    "399.165\n",
    "1.06605465715\n",
    "410.023\n",
    "1.0615075232\n",
    "394.306\n",
    "1.05856999806\n",
    "384.527\n",
    "1.06017399057"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
