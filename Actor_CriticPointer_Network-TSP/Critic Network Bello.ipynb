{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tsp_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(W_ref, W_q, v, enc_outputs, query):\n",
    "    with tf.variable_scope(\"attention_mask\"):\n",
    "        u_i0s = tf.einsum('kl,itl->itk', W_ref, enc_outputs)\n",
    "        u_i1s = tf.expand_dims(tf.einsum('kl,il->ik', W_q, query), 1)\n",
    "        u_is = tf.einsum('k,itk->it', v, tf.tanh(u_i0s + u_i1s))\n",
    "        return tf.einsum('itk,it->ik', enc_outputs, tf.nn.softmax(u_is))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_network(enc_inputs, \n",
    "                   hidden_size = 128, embedding_size = 128,\n",
    "                   max_time_steps = 5, input_size = 2,\n",
    "                   batch_size = 128,\n",
    "                   initialization_stddev = 0.1,\n",
    "                   n_processing_steps = 5, d = 128):\n",
    "    # Embed inputs in larger dimensional tensors\n",
    "    W_embed = tf.Variable(tf.random_normal([embedding_size, input_size],\n",
    "                                           stddev=initialization_stddev))\n",
    "    embedded_inputs = tf.einsum('kl,itl->itk', W_embed, enc_inputs)\n",
    "\n",
    "    # Define encoder\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        enc_rnn_cell = tf.nn.rnn_cell.LSTMCell(hidden_size)\n",
    "        enc_outputs, enc_final_state = tf.nn.dynamic_rnn(cell=enc_rnn_cell,\n",
    "                                                         inputs=embedded_inputs,\n",
    "                                                         dtype=tf.float32)\n",
    "    # Define process block\n",
    "    with tf.variable_scope(\"process_block\"):\n",
    "        process_cell = tf.nn.rnn_cell.LSTMCell(hidden_size)\n",
    "        first_process_block_input = tf.tile(tf.Variable(tf.random_normal([1, embedding_size]),\n",
    "                                                        name='first_process_block_input'), \n",
    "                                            [batch_size, 1])\n",
    "        # Define attention weights\n",
    "        with tf.variable_scope(\"attention_weights\", reuse=True):\n",
    "            W_ref = tf.Variable(tf.random_normal([embedding_size, embedding_size],\n",
    "                                                 stddev=initialization_stddev),\n",
    "                                name='W_ref')\n",
    "            W_q = tf.Variable(tf.random_normal([embedding_size, embedding_size],\n",
    "                                               stddev=initialization_stddev),\n",
    "                              name='W_q')\n",
    "            v = tf.Variable(tf.random_normal([embedding_size], stddev=initialization_stddev),\n",
    "                            name='v')\n",
    "\n",
    "        # Processing chain\n",
    "        processing_state = enc_final_state\n",
    "        processing_input = first_process_block_input\n",
    "        for t in range(n_processing_steps):\n",
    "            processing_cell_output, processing_state = process_cell(inputs=processing_input,\n",
    "                                                                   state=processing_state)\n",
    "            processing_input = attention(W_ref, W_q, v, \n",
    "                                         enc_outputs=enc_outputs, query=processing_cell_output)\n",
    "\n",
    "\n",
    "    # Apply 2 layers of ReLu for decoding the processed state\n",
    "    return tf.squeeze(tf.layers.dense(inputs=tf.layers.dense(inputs=processing_cell_output,\n",
    "                                                  units=d, activation=tf.nn.relu),\n",
    "                           units=1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128; max_time_steps = 5; input_size = 2\n",
    "enc_inputs = tf.placeholder(tf.float32, [batch_size, max_time_steps, input_size])\n",
    "bsln_value = critic_network(enc_inputs,\n",
    "                            hidden_size = 128, embedding_size = 128,\n",
    "                            max_time_steps = 5, input_size = 2,\n",
    "                            batch_size = 128,\n",
    "                            initialization_stddev = 0.1,\n",
    "                            n_processing_steps = 5, d = 128)\n",
    "tours_rewards_ph = tf.placeholder(tf.float32, [batch_size])\n",
    "loss = tf.losses.mean_squared_error(labels=tours_rewards_ph,\n",
    "                                    predictions=bsln_value)\n",
    "train_op = tf.train.AdamOptimizer(1e-2).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.34178\n",
      "0.154837\n",
      "0.139899\n",
      "0.0980297\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c6b3b1ce72ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     loss_val, _ = sess.run([loss, train_op],\n\u001b[1;32m     22\u001b[0m                           feed_dict={enc_inputs: inputs_batch,\n\u001b[0;32m---> 23\u001b[0;31m                                      tours_rewards_ph: labels_batch})\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mloss_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aurelien.bibaut@gmail.com/Data_PC/PhD_Berkeley/Courses/Deep_Reinforcement_Learning/deep_rl2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aurelien.bibaut@gmail.com/Data_PC/PhD_Berkeley/Courses/Deep_Reinforcement_Learning/deep_rl2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aurelien.bibaut@gmail.com/Data_PC/PhD_Berkeley/Courses/Deep_Reinforcement_Learning/deep_rl2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aurelien.bibaut@gmail.com/Data_PC/PhD_Berkeley/Courses/Deep_Reinforcement_Learning/deep_rl2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aurelien.bibaut@gmail.com/Data_PC/PhD_Berkeley/Courses/Deep_Reinforcement_Learning/deep_rl2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Trying it out: can we learn the reward of the optimal policy for the TSP5? #\n",
    "##############################################################################\n",
    "def generate_batch(n_cities, batch_size):\n",
    "    inputs_list = []; labels_list = []\n",
    "    env = tsp_env.TSP_env(n_cities, use_alternative_state=True)\n",
    "    for i in range(batch_size):\n",
    "        env.reset()\n",
    "        s = env.reset()\n",
    "        coords = s.reshape([4, n_cities])[:2, ].T\n",
    "        inputs_list.append(coords)\n",
    "        labels_list.append(env.optimal_solution()[0])\n",
    "    return np.array(inputs_list), np.array(labels_list)\n",
    "# Create tf session and initialize variables\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "# Training loop\n",
    "loss_vals = []\n",
    "for i in range(10000):\n",
    "    inputs_batch, labels_batch = generate_batch(max_time_steps, batch_size)\n",
    "    loss_val, _ = sess.run([loss, train_op],\n",
    "                          feed_dict={enc_inputs: inputs_batch,\n",
    "                                     tours_rewards_ph: labels_batch})\n",
    "    loss_vals.append(loss_val)\n",
    "    if i % 50 == 0:\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(np.log(loss_vals_slow_lr))\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Log of mean squared error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
